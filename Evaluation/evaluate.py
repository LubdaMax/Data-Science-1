import numpy as np
import pandas as pd
import os
import nltk
from nltk.corpus import stopwords
from nltk import f_measure
from nltk.metrics.scores import recall
from nltk.metrics.scores import precision
from pathlib import Path
import re
import pickle
import string
from rouge import Rouge
import sklearn
from sklearn.naive_bayes import BernoulliNB
from sklearn.naive_bayes import GaussianNB
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression


## indicat what method is evaluated: textrank or naivebayes
method = "textrank"

rootpath = Path.cwd()

## open data for reference summaries:
open_cnn_summ = open(Path.joinpath(rootpath, r"Pre-Processing & EDA\cnn_summaries_dict"), 'rb')
cnn_summary = pickle.load(open_cnn_summ)
open_cnn_summ.close()

open_wiki_summ = open(Path.joinpath(rootpath, r"Wikihow\wiki_partial_summaries_10k"), 'rb')
wiki_summary = pickle.load(open_wiki_summ)
open_wiki_summ.close()

if method == "naivebayes":
    ## open data for output summaries generated by NAIVE BAISE
    openfile = open(Path.joinpath(rootpath, r"Gauss_trained_10_no_overview_notitle_10k"), 'rb')
    GaussNB = pickle.load(openfile)
    openfile.close()

    open_wiki = open(Path.joinpath(rootpath, r"Wikihow\wiki_data_indep_8_no_overview_notilte_10k"), 'rb')
    wiki_data = pickle.load(open_wiki)
    open_wiki.close()

    open_cnn_article = open(Path.joinpath(rootpath, r"cnn_indep_8"), 'rb')
    cnn_data = pickle.load(open_cnn_article)
    open_cnn_article.close()

elif method == "textrank":
    # open data for output summaries generated by TEXTRANK
    openfile = open(Path.joinpath(rootpath, r"LexRank\wiki_TRoutput_summ_dict"), 'rb')
    wiki_data = pickle.load(openfile)
    openfile.close()

    openfile = open(Path.joinpath(rootpath, r"LexRank\cnn_TRoutput_summ_dict"), 'rb')
    cnn_data = pickle.load(openfile)
    openfile.close()

    openfile = open(Path.joinpath(rootpath, r"LexRank\cnn_TRoutput_ranking_dict"), 'rb')
    cnn_data_TotalRanking = pickle.load(openfile)
    openfile.close()




def get_summ(dictionary):
    Summaries = []
    for i in range(len(dictionary)):
        Summary = ""

        for s in range(dictionary["Summary{0}".format(i)].shape[0]):
            Summary += dictionary["Summary{0}".format(i)].iloc[s, 0]
            Summary += " "

        Summary = Summary[:-1]
        Summaries.append(Summary)
    return Summaries


def get_summ_wiki(dictionary):
    Summaries = []

    for i in range(len(dictionary)):
        Summary = dictionary["Summary{0}".format(i)]
        Summaries.append(Summary)
    return Summaries


def create_summ_NB_cnn(dictionary):
    Summaries = []

    for i in range(1,len(dictionary)):
        article = dictionary["Article{0}".format(i)]
        article_props = dictionary["Article{0}".format(i)].drop(["sentence"], axis=1)
        Summary_class = GaussNB.predict(article_props)
        Summary = ""

        for s in range(len(Summary_class)):
            if Summary_class[s] == 1:
                Summary += article.iloc[s, 0]
                Summary += " "
        Summary = Summary[:-1]
        Summaries.append(Summary)

    return Summaries


def create_summ_NB_wiki(dictionary):
    Summaries = []

    for i in range(len(dictionary)):
        article = dictionary["Article{0}".format(i)]
        article_props = dictionary["Article{0}".format(i)].drop(["sentence", "in_Summary"], axis=1)
        Summary_class = GaussNB.predict(article_props)
        Summary = ""

        for s in range(len(Summary_class)):
            if Summary_class[s] == 1:
                Summary += article.iloc[s, 0]
                Summary += " "
        Summary = Summary[:-1]
        Summaries.append(Summary)

    return Summaries



def create_summ_TR(ranked_sentences_dict, article_key, article_data, number_sentences):
    """ generates output summary specifically from the TextRank Output

    :param ranked_sentences_dict: dictionary, that ranks importance sentences {sss:sss,}
    :param article_key:
    :param article_data:
    :param number_sentences: number of sentences in Summary
    :return:
    """
    summary = []
    for i in range(number_sentences):
        s = ranked_sentences_dict[article_key][i][0]
        summary.append(article_data[article_key].iloc[s, 0])
        summary.append(" ")

        summary = "".join(summary)

    return summary




def eval_summ(cnn_summary, cnn_data, wiki_summary, wiki_data):
    cnn_summ = get_summ(cnn_summary)
    cnn_generated_summ = create_summ_NB_cnn(cnn_data)
    wiki_summ = get_summ_wiki(wiki_summary)
    wiki_generated_summ = create_summ_NB_wiki(wiki_data)
    rouge = Rouge()

    cnn_score_frame = pd.DataFrame(columns=["r1-f", "r1-p", "r1-r", "r2-f", "r2-p", "r2-r", "rl-f", "rl-p", "rl-r"])
    for i in range(len(cnn_summary)):
        # score = recall(nltk.sent_tokenize(cnn_summ[i]), nltk.sent_tokenize(cnn_generated_summ[i]))
        if (len(cnn_summary[i]) and len(cnn_data[i])) > 0:
            try:
                score = rouge.get_scores(cnn_summary[i], cnn_data[i])

                cnn_score_frame = cnn_score_frame.append(pd.DataFrame(
                    {'r1-f': score[0]['rouge-1']['f'], 'r1-p': score[0]['rouge-1']['p'],
                     'r1-r': score[0]['rouge-1']['r'], 'r2-f': score[0]['rouge-2']['f'],
                     'r2-p': score[0]['rouge-2']['p'], 'r2-r': score[0]['rouge-2']['r'],
                     'rl-f': score[0]['rouge-l']['f'], 'rl-p': score[0]['rouge-l']['p'],
                     'rl-r': score[0]['rouge-l']['r']}, index=[0]), ignore_index=True)
            except:
                print("summary: ", cnn_summary[i])
                print("generated: ", cnn_data[i])
                print(
                    "------------------------------------------------------------------------------------------------------------------------")

    wiki_score_frame = pd.DataFrame(columns=["r1-f", "r1-p", "r1-r", "r2-f", "r2-p", "r2-r", "rl-f", "rl-p", "rl-r"])
    for i in range(len(wiki_summary)):
        # score = recall(nltk.sent_tokenize(cnn_summ[i]), nltk.sent_tokenize(cnn_generated_summ[i]))
        if (len(wiki_summary[i]) and len(wiki_data[i])) > 0:
            score = rouge.get_scores(wiki_summary[i], wiki_data[i])

            wiki_score_frame = wiki_score_frame.append(pd.DataFrame(
                {'r1-f': score[0]['rouge-1']['f'], 'r1-p': score[0]['rouge-1']['p'], 'r1-r': score[0]['rouge-1']['r'],
                 'r2-f': score[0]['rouge-2']['f'], 'r2-p': score[0]['rouge-2']['p'], 'r2-r': score[0]['rouge-2']['r'],
                 'rl-f': score[0]['rouge-l']['f'], 'rl-p': score[0]['rouge-l']['p'], 'rl-r': score[0]['rouge-l']['r']},
                index=[0]), ignore_index=True)

    return wiki_score_frame, cnn_score_frame


## EVALUATION
if method == "naivebayes":

    ## generate input required for evaulation method: NAIVE BAYES
    cnn_summ = get_summ(cnn_summary)
    cnn_generated_summ = create_summ_NB_cnn(cnn_data)
    wiki_summ = get_summ_wiki(wiki_summary)
    wiki_generated_summ = create_summ_NB_wiki(wiki_data)

    ##evaluate performance NAIVE BAYES
    wiki_score, cnn_score = eval_summ(cnn_summ, cnn_generated_summ, wiki_summ, wiki_generated_summ)
    print(wiki_score.head(), wiki_score.shape)
    print("r1-f mean: ", wiki_score["r1-f"].mean())
    print("r2-f mean: ", wiki_score["r2-f"].mean())
    print("rl-f mean: ", wiki_score["rl-f"].mean())
    print(cnn_score.head(), cnn_score.shape)
    print("r1-f mean: ", cnn_score["r1-f"].mean())
    print("r2-f mean: ", cnn_score["r2-f"].mean())
    print("rl-f mean: ", cnn_score["rl-f"].mean())


elif method == "textrank":
    ## generate input required for evaulation method: TEXTRANK
    cnn_summ = get_summ(cnn_summary)
    cnn_generated_summ = get_summ(cnn_data)
    # wiki_summ = get_summ_wiki(wiki_summary)
    wiki_generated_summ = get_summ(wiki_data)
    print(cnn_data)

    print("cnn_ref: ", cnn_summ[0])
    print(len(cnn_summ))
    print("cnn_out: ",cnn_generated_summ[0])
    print(len(cnn_generated_summ))




    ##evaluate performance TEXTRANK
    #wiki_score, cnn_score = eval_summ(cnn_summ, cnn_generated_summ, wiki_summ, wiki_generated_summ)
    # print(wiki_score.head(), wiki_score.shape)
    # print("r1-f mean: ", wiki_score["r1-f"].mean())
    # print("r2-f mean: ", wiki_score["r2-f"].mean())
    # print("rl-f mean: ", wiki_score["rl-f"].mean())
    # print(cnn_score.head(), cnn_score.shape)
    # print("r1-f mean: ", cnn_score["r1-f"].mean())
    # print("r2-f mean: ", cnn_score["r2-f"].mean())
    # print("rl-f mean: ", cnn_score["rl-f"].mean())


